{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "11569e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from torch.nn import Module\n",
    "from torch.nn import Conv2d\n",
    "from torch.nn import Linear\n",
    "from torch.nn import MaxPool2d\n",
    "from torch.nn import ReLU\n",
    "from torch.nn import LogSoftmax\n",
    "from torch import flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d2a45841",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet(Module):\n",
    "\tdef __init__(self, numChannels, classes):\n",
    "\t\t# call the parent constructor\n",
    "\t\tsuper(LeNet, self).__init__()\n",
    "\t\t# initialize first set of CONV => RELU => POOL layers\n",
    "\t\tself.conv1 = Conv2d(in_channels=numChannels, out_channels=20,\n",
    "\t\t\tkernel_size=(5, 5))\n",
    "\t\tself.relu1 = ReLU()\n",
    "\t\tself.maxpool1 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\t\t# initialize second set of CONV => RELU => POOL layers\n",
    "\t\tself.conv2 = Conv2d(in_channels=20, out_channels=50,\n",
    "\t\t\tkernel_size=(5, 5))\n",
    "\t\tself.relu2 = ReLU()\n",
    "\t\tself.maxpool2 = MaxPool2d(kernel_size=(2, 2), stride=(2, 2))\n",
    "\t\t# initialize first (and only) set of FC => RELU layers\n",
    "\t\tself.fc1 = Linear(in_features=186050, out_features=64)\n",
    "\t\tself.relu3 = ReLU()\n",
    "\t\t# initialize our softmax classifier\n",
    "\t\tself.fc2 = Linear(in_features=64, out_features=classes)\n",
    "\t\tself.logSoftmax = LogSoftmax(dim=1)\n",
    "\tdef forward(self, x):\n",
    "\t\t# pass the input through our first set of CONV => RELU =>\n",
    "\t\t# POOL layers\n",
    "\t\tx = self.conv1(x)\n",
    "\t\tx = self.relu1(x)\n",
    "\t\tx = self.maxpool1(x)\n",
    "\t\t# pass the output from the previous layer through the second\n",
    "\t\t# set of CONV => RELU => POOL layers\n",
    "\t\tx = self.conv2(x)\n",
    "\t\tx = self.relu2(x)\n",
    "\t\tx = self.maxpool2(x)\n",
    "\t\t# flatten the output from the previous layer and pass it\n",
    "\t\t# through our only set of FC => RELU layers\n",
    "\t\tx = flatten(x, 1)\n",
    "\t\tx = self.fc1(x)\n",
    "\t\tx = self.relu3(x)\n",
    "\t\t# pass the output to our softmax classifier to get our output\n",
    "\t\t# predictions\n",
    "\t\tx = self.fc2(x)\n",
    "\t\toutput = self.logSoftmax(x)\n",
    "\t\t# return the output predictions\n",
    "\t\treturn output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7491f950",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the matplotlib backend so figures can be saved in the background\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "# import the necessary packages\n",
    "from sklearn.metrics import classification_report\n",
    "from torch.utils.data import random_split\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.optim import Adam\n",
    "from torch import nn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import argparse\n",
    "import torch\n",
    "import time\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "809e0977",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate command-line arguments inside the notebook\n",
    "args_list = ['-m', 'model_output.h5', '-p', 'plot_output.png']\n",
    "\n",
    "# construct the argument parser and parse the arguments\n",
    "ap = argparse.ArgumentParser()\n",
    "ap.add_argument(\"-m\", \"--model\", type=str, required=True,\n",
    "\thelp=\"path to output trained model\", default='model_output.h5')\n",
    "ap.add_argument(\"-p\", \"--plot\", type=str, required=True,\n",
    "\thelp=\"path to output loss/accuracy plot\", default='plot_output.png')\n",
    "args = vars(ap.parse_args(args_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "2435a4a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training hyperparameters\n",
    "INIT_LR = 1e-3\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 10\n",
    "# define the train and val splits\n",
    "TRAIN_SPLIT = 0.75\n",
    "VAL_SPLIT = 1 - TRAIN_SPLIT\n",
    "# set the device we will be using to train the model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "280fcbdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new class to replace KMNIST with our data\n",
    "class CustomFolderDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        \n",
    "        # Map folder names to labels\n",
    "        self.classes = sorted(os.listdir(root_dir))\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.classes)}\n",
    "        \n",
    "        # Collect all (image_path, label) pairs\n",
    "        self.samples = []\n",
    "        for cls_name in self.classes:\n",
    "            cls_folder = os.path.join(root_dir, cls_name)\n",
    "            for fname in os.listdir(cls_folder):\n",
    "                if fname.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp')):\n",
    "                    path = os.path.join(cls_folder, fname)\n",
    "                    label = self.class_to_idx[cls_name]\n",
    "                    self.samples.append((path, label))\n",
    "        \n",
    "        self.targets = [label for _, label in self.samples]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, label = self.samples[idx]\n",
    "        image = Image.open(img_path)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7123f0db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading the KMNIST dataset...\n",
      "[INFO] generating the train/validation split...\n"
     ]
    }
   ],
   "source": [
    "# load the KMNIST dataset\n",
    "print(\"[INFO] loading the KMNIST dataset...\")\n",
    "trainData = CustomFolderDataset(root_dir='./Hey-Waldo/256', transform=ToTensor())\n",
    "testData = CustomFolderDataset(root_dir='./Hey-Waldo/256', transform=ToTensor())\n",
    "# calculate the train/validation split\n",
    "print(\"[INFO] generating the train/validation split...\")\n",
    "numTrainSamples = int(len(trainData) * TRAIN_SPLIT)\n",
    "numValSamples = len(trainData) - numTrainSamples\n",
    "(trainData, valData) = random_split(trainData,\n",
    "\t[numTrainSamples, numValSamples],\n",
    "\tgenerator=torch.Generator().manual_seed(42))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3fe57c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the train, validation, and test data loaders\n",
    "trainDataLoader = DataLoader(trainData, shuffle=True,\n",
    "\tbatch_size=BATCH_SIZE)\n",
    "valDataLoader = DataLoader(valData, batch_size=BATCH_SIZE)\n",
    "testDataLoader = DataLoader(testData, batch_size=BATCH_SIZE)\n",
    "# calculate steps per epoch for training and validation set\n",
    "trainSteps = len(trainDataLoader.dataset) // BATCH_SIZE\n",
    "valSteps = len(valDataLoader.dataset) // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "e85d01b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unused code that we could make a custom CNN from (sourced from HW 4)\n",
    "# Assumed start of 64 pixels\n",
    "def createCnnSequential():\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=8, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, padding=1),\n",
    "        nn.ReLU(),\n",
    "        nn.MaxPool2d(2),\n",
    "        nn.Flatten(),\n",
    "        nn.Linear(4096,256),\n",
    "        nn.ReLU(),\n",
    "        nn.Linear(256, 2)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "e7acd2ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] initializing the model...\n",
      "[INFO] training the network...\n",
      "[INFO] EPOCH: 1/10\n",
      "Train loss: 9.412308, Train accuracy: 0.5359\n",
      "Val loss: 1.227269, Val accuracy: 0.9000\n",
      "\n",
      "[INFO] EPOCH: 2/10\n",
      "Train loss: 0.971994, Train accuracy: 0.9030\n",
      "Val loss: 1.309961, Val accuracy: 0.9000\n",
      "\n",
      "[INFO] EPOCH: 3/10\n",
      "Train loss: 0.905338, Train accuracy: 0.9030\n",
      "Val loss: 1.229573, Val accuracy: 0.9000\n",
      "\n",
      "[INFO] EPOCH: 4/10\n",
      "Train loss: 0.929635, Train accuracy: 0.9030\n",
      "Val loss: 1.220439, Val accuracy: 0.9000\n",
      "\n",
      "[INFO] EPOCH: 5/10\n",
      "Train loss: 0.874210, Train accuracy: 0.9030\n",
      "Val loss: 1.204914, Val accuracy: 0.9125\n",
      "\n",
      "[INFO] EPOCH: 6/10\n",
      "Train loss: 0.809571, Train accuracy: 0.9198\n",
      "Val loss: 1.109525, Val accuracy: 0.9125\n",
      "\n",
      "[INFO] EPOCH: 7/10\n",
      "Train loss: 0.687188, Train accuracy: 0.9451\n",
      "Val loss: 0.978368, Val accuracy: 0.9375\n",
      "\n",
      "[INFO] EPOCH: 8/10\n",
      "Train loss: 0.824218, Train accuracy: 0.6920\n",
      "Val loss: 0.975936, Val accuracy: 0.8750\n",
      "\n",
      "[INFO] EPOCH: 9/10\n",
      "Train loss: 0.538658, Train accuracy: 0.9409\n",
      "Val loss: 0.931014, Val accuracy: 0.9250\n",
      "\n",
      "[INFO] EPOCH: 10/10\n",
      "Train loss: 0.451578, Train accuracy: 1.0000\n",
      "Val loss: 0.946466, Val accuracy: 0.9125\n",
      "\n",
      "[INFO] total time taken to train the model: 96.53s\n",
      "[INFO] evaluating network...\n"
     ]
    }
   ],
   "source": [
    "# initialize the model\n",
    "from sklearn.utils import compute_class_weight\n",
    "\n",
    "print(\"[INFO] initializing the model...\")\n",
    "# model = createCnnSequential().to(device)\n",
    "model = LeNet(\n",
    "\tnumChannels=3,\n",
    "\tclasses=len(trainData.dataset.classes)).to(device)\n",
    "\n",
    "# Access correct targets from the split subset\n",
    "full_targets = trainData.dataset.targets\n",
    "train_targets = [full_targets[i] for i in trainData.indices]\n",
    "\n",
    "# Compute weights\n",
    "class_weights = compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(train_targets),\n",
    "    y=train_targets\n",
    ")\n",
    "\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "# initialize our optimizer and loss function\n",
    "opt = Adam(model.parameters(), lr=INIT_LR)\n",
    "lossFn = nn.CrossEntropyLoss(weight=class_weights)\n",
    "# initialize a dictionary to store training history\n",
    "H = {\n",
    "\t\"train_loss\": [],\n",
    "\t\"train_acc\": [],\n",
    "\t\"val_loss\": [],\n",
    "\t\"val_acc\": []\n",
    "}\n",
    "# measure how long training is going to take\n",
    "print(\"[INFO] training the network...\")\n",
    "startTime = time.time()\n",
    "\n",
    "# loop over our epochs\n",
    "for e in range(0, EPOCHS):\n",
    "\t# set the model in training mode\n",
    "\tmodel.train()\n",
    "\t# initialize the total training and validation loss\n",
    "\ttotalTrainLoss = 0\n",
    "\ttotalValLoss = 0\n",
    "\t# initialize the number of correct predictions in the training\n",
    "\t# and validation step\n",
    "\ttrainCorrect = 0\n",
    "\tvalCorrect = 0\n",
    "\t# loop over the training set\n",
    "\tfor (x, y) in trainDataLoader:\n",
    "\t\t# send the input to the device\n",
    "\t\t(x, y) = (x.to(device), y.to(device))\n",
    "\t\t# perform a forward pass and calculate the training loss\n",
    "\t\tpred = model(x)\n",
    "\t\tloss = lossFn(pred, y)\n",
    "\t\t# zero out the gradients, perform the backpropagation step,\n",
    "\t\t# and update the weights\n",
    "\t\topt.zero_grad()\n",
    "\t\tloss.backward()\n",
    "\t\topt.step()\n",
    "\t\t# add the loss to the total training loss so far and\n",
    "\t\t# calculate the number of correct predictions\n",
    "\t\ttotalTrainLoss += loss\n",
    "\t\ttrainCorrect += (pred.argmax(1) == y).type(\n",
    "\t\t\ttorch.float).sum().item()\n",
    "\t# switch off autograd for evaluation\n",
    "\twith torch.no_grad():\n",
    "\t\t# set the model in evaluation mode\n",
    "\t\tmodel.eval()\n",
    "\t\t# loop over the validation set\n",
    "\t\tfor (x, y) in valDataLoader:\n",
    "\t\t\t# send the input to the device\n",
    "\t\t\t(x, y) = (x.to(device), y.to(device))\n",
    "\t\t\t# make the predictions and calculate the validation loss\n",
    "\t\t\tpred = model(x)\n",
    "\t\t\ttotalValLoss += lossFn(pred, y)\n",
    "\t\t\t# calculate the number of correct predictions\n",
    "\t\t\tvalCorrect += (pred.argmax(1) == y).type(\n",
    "\t\t\t\ttorch.float).sum().item()\n",
    "\t# calculate the average training and validation loss\n",
    "\tavgTrainLoss = totalTrainLoss / trainSteps\n",
    "\tavgValLoss = totalValLoss / valSteps\n",
    "\t# calculate the training and validation accuracy\n",
    "\ttrainCorrect = trainCorrect / len(trainDataLoader.dataset)\n",
    "\tvalCorrect = valCorrect / len(valDataLoader.dataset)\n",
    "\t# update our training history\n",
    "\tH[\"train_loss\"].append(avgTrainLoss.cpu().detach().numpy())\n",
    "\tH[\"train_acc\"].append(trainCorrect)\n",
    "\tH[\"val_loss\"].append(avgValLoss.cpu().detach().numpy())\n",
    "\tH[\"val_acc\"].append(valCorrect)\n",
    "\t# print the model training and validation information\n",
    "\tprint(\"[INFO] EPOCH: {}/{}\".format(e + 1, EPOCHS))\n",
    "\tprint(\"Train loss: {:.6f}, Train accuracy: {:.4f}\".format(\n",
    "\t\tavgTrainLoss, trainCorrect))\n",
    "\tprint(\"Val loss: {:.6f}, Val accuracy: {:.4f}\\n\".format(\n",
    "\t\tavgValLoss, valCorrect))\n",
    "\n",
    "# finish measuring how long training took\n",
    "endTime = time.time()\n",
    "print(\"[INFO] total time taken to train the model: {:.2f}s\".format(\n",
    "\tendTime - startTime))\n",
    "# we can now evaluate the network on the test set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "# turn off autograd for testing evaluation\n",
    "with torch.no_grad():\n",
    "\t# set the model in evaluation mode\n",
    "\tmodel.eval()\n",
    "\t\n",
    "\t# initialize a list to store our predictions\n",
    "\tpreds = []\n",
    "\t# loop over the test set\n",
    "\tfor (x, y) in testDataLoader:\n",
    "\t\t# send the input to the device\n",
    "\t\tx = x.to(device)\n",
    "\t\t# make the predictions and add them to the list\n",
    "\t\tpred = model(x)\n",
    "\t\tpreds.extend(pred.argmax(axis=1).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8c49b304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    notwaldo       0.97      1.00      0.98       286\n",
      "       waldo       0.96      0.74      0.84        31\n",
      "\n",
      "    accuracy                           0.97       317\n",
      "   macro avg       0.97      0.87      0.91       317\n",
      "weighted avg       0.97      0.97      0.97       317\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# generate a classification report\n",
    "print(classification_report(testData.targets,\n",
    "\tnp.array(preds), target_names=testData.classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b152c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training loss and accuracy\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(H[\"train_loss\"], label=\"train_loss\")\n",
    "plt.plot(H[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(H[\"train_acc\"], label=\"train_acc\")\n",
    "plt.plot(H[\"val_acc\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy on Dataset\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "\n",
    "plt.savefig(args[\"plot\"])\n",
    "# serialize the model to disk\n",
    "torch.save(model, args[\"model\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bed214db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def load_image(path):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    return img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51e4a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_window(image, step=32, window_size=(128, 128)):\n",
    "    for y in range(0, image.shape[0] - window_size[1], step):\n",
    "        for x in range(0, image.shape[1] - window_size[0], step):\n",
    "            yield (x, y, image[y:y + window_size[1], x:x + window_size[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3590c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_waldo_in_image(model, full_image, window_size=(128, 128), step=32, threshold=0.9):\n",
    "    boxes = []\n",
    "\n",
    "    for (x, y, window) in sliding_window(full_image, step=step, window_size=window_size):\n",
    "        if window.shape[0] != window_size[1] or window.shape[1] != window_size[0]:\n",
    "            continue  # Skip incomplete patches at the edge\n",
    "\n",
    "        input_img = tf.image.resize(window, window_size)\n",
    "        input_img = tf.expand_dims(input_img / 255.0, axis=0)  # Normalize\n",
    "\n",
    "        prediction = model.predict(input_img, verbose=0)[0][0]\n",
    "\n",
    "        if prediction >= threshold:\n",
    "            boxes.append((x, y, prediction))\n",
    "\n",
    "    return boxes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f9e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_detections(image, boxes, window_size=(128, 128)):\n",
    "    img_copy = image.copy()\n",
    "    for (x, y, score) in boxes:\n",
    "        cv2.rectangle(img_copy, (x, y), (x + window_size[0], y + window_size[1]), (255, 0, 0), 2)\n",
    "        cv2.putText(img_copy, f\"{score:.2f}\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)\n",
    "    return img_copy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe385031",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_path = \"Hey-Waldo/original-images/1.jpg\"\n",
    "# img_path = \"Hey-Waldo/256/waldo/1_1_1.jpg\"\n",
    "image = load_image(img_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b810b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = 0, 0\n",
    "test_window = image[y:y+128, x:x+128]  # Pick a spot you know Waldo is in\n",
    "test_window = cv2.resize(test_window, (128, 128))\n",
    "test_window = test_window.astype(\"float32\") / 255.0\n",
    "test_window = np.expand_dims(test_window, axis=0)\n",
    "\n",
    "prediction = model.predict(test_window)\n",
    "print(\"Prediction score:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4398ab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example threshold values\n",
    "threshold = 0.7\n",
    "\n",
    "# Multiply by 100000 to shift the decimal point\n",
    "# threshold_display = int(threshold * 1000000)\n",
    "\n",
    "# Display as 15 instead of 0.00015\n",
    "# print(f\"Threshold: {threshold_display}\")\n",
    "\n",
    "boxes = detect_waldo_in_image(model, image, window_size=(256, 256), step=128, threshold=threshold)\n",
    "# for some reason every single bounding box has the same threshold value???\n",
    "\n",
    "result_image = draw_detections(image, boxes)\n",
    "\n",
    "# plt.figure(figsize=(12, 12))\n",
    "# plt.title(f\"Threshold: {threshold_display}\")\n",
    "plt.imshow(result_image)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
